# Контрольные вопросы к Assignment 4
## 1. В чём заключается отличие гибридных вычислений от вычислений только на CPU или только на GPU?

* **CPU-only**: вычисления выполняются полностью на центральном процессоре. Подходит для последовательных или слабо параллельных задач, но имеет ограниченную пропускную способность для массивных параллельных операций.
* **GPU-only**: вычисления выполняются полностью на графическом процессоре. Отличается высокой пропускной способностью и подходит для массово параллельных операций, но менее эффективен для задач с сильными ветвлениями или зависимостями.
* **Гибридные вычисления (CPU + GPU)**: часть задач выполняется на CPU, часть — на GPU одновременно. Позволяет максимально использовать все доступные ресурсы системы, снижает простой устройств и ускоряет обработку.
**Ключевая идея:** CPU обрабатывает те части, где он силен (логика, ветвления), GPU — где нужна массовая параллельность, а вместе они могут работать параллельно.

## 2. Для каких типов задач целесообразно распределять вычисления между CPU и GPU?

* Массово параллельные вычисления, например:
  * Векторные и матричные операции
  * Обработка больших массивов данных
  * Симуляции и физические модели
* Задачи, где часть операций лучше выполнять на CPU (логика, I/O) и часть на GPU (численные массивные операции).
* Задачи с **разделяемыми данными**, которые могут обрабатываться частями без сильных зависимостей.

## 3. В чём разница между синхронной и асинхронной передачей данных между CPU и GPU?

* **Синхронная (blocking)**:
  * CPU ждёт завершения передачи данных до продолжения работы.
  * Пример: `cudaMemcpy()` без `cudaMemcpyAsync`.
* **Асинхронная (non-blocking)**:
  * CPU может продолжать выполнять свои задачи, пока данные передаются на GPU.
  * Пример: `cudaMemcpyAsync()` с использованием потоков CUDA.

**Ключевое отличие:** синхронная передача блокирует CPU, асинхронная позволяет перекрывать передачу данных с вычислениями.

## 4. Почему асинхронная передача данных может повысить производительность программы?

* Позволяет **перекрывать вычисления с передачей данных**: пока GPU обрабатывает одну порцию данных, CPU уже готовит следующую.
* Снижает простой CPU и GPU, улучшает **использование всех ресурсов системы**.
* Особенно эффективно для больших массивов или многопоточных задач.

## 5. Какие основные функции MPI используются для распределения и сбора данных между процессами?

* `MPI_Scatter` — раздаёт части массива (или данных) каждому процессу.
* `MPI_Gather` — собирает результаты с всех процессов в один массив на главном процессе.
* `MPI_Reduce` — выполняет агрегирование данных (например, сумму, максимум) на всех процессах.
* `MPI_Bcast` — рассылает данные от главного процесса ко всем остальным.
* `MPI_Send` / `MPI_Recv` — базовые функции для отправки и получения сообщений между процессами.

## 6. Как количество процессов MPI влияет на время выполнения программы и почему?

* Увеличение числа процессов **может ускорить выполнение** за счёт распараллеливания работы.
* Но есть **ограничения**:
  * Если процессов слишком много, то накладные расходы на коммуникацию (`MPI_Send/MPI_Recv`) начинают превышать выигрыш.
  * Малые объёмы данных при большом количестве процессов приводят к снижению эффективности.
* **Оптимальное число процессов** зависит от размера задачи и архитектуры системы.

## 7. Какие факторы ограничивают масштабируемость распределённых параллельных программ?

* **Накладные расходы на коммуникацию** между процессами.
* **Баланс нагрузки**: если данные распределены неравномерно, часть процессов простаивает.
* **Зависимости данных** между процессами (нужны синхронизации).
* **Ограничения сети и пропускной способности** для распределённых систем.
* **Инициализация и завершение MPI** — требует времени, особенно при больших количествах процессов.

## 8. В каких случаях использование распределённых вычислений оправдано, а в каких — неэффективно?

**Оправдано, если:**
* Очень большие объёмы данных, которые не помещаются в память одного узла.
* Задача легко распараллеливается без сильных зависимостей.
* Требуется ускорение за счёт нескольких узлов/процессоров.
**Неэффективно, если:**
* Данные малы и накладные расходы на коммуникацию превышают выигрыш.
* Задача сильно последовательная, с большим количеством зависимостей.
* Частые синхронизации и обмен данными между процессами замедляют вычисления.

