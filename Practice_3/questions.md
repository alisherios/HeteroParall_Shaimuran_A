# Контрольные вопросы к Практическая работа №3 Реализация более сложных алгоритмов сортировки (слияние, быстрая, пирамидальная) на GPU с использованием CUDA

## 1. В чем различие между последовательной и параллельной реализациями сортировки слиянием?

* **Последовательная реализация** выполняется на CPU: массив рекурсивно делится на подмассивы, которые сортируются один за другим, а затем последовательно сливаются. Весь процесс занимает один поток и не использует возможности параллельного выполнения.
* **Параллельная реализация** на GPU/CUDA разделяет массив на блоки, каждый из которых обрабатывается отдельным блоком потоков. Подмассивы сортируются одновременно, а слияние может происходить параллельно по парам блоков, что позволяет ускорить обработку больших данных.

## 2. Как распределение потоков и блоков влияет на производительность на CUDA?

* На GPU задачи распределяются на сетку (Grid) блоков, каждый блок содержит несколько потоков (Threads).
* Производительность зависит от загрузки **SM (Streaming Multiprocessors)**:

  * слишком мало потоков → вычислительные ядра простаивают;
  * слишком много потоков → растет накладная стоимость управления и возможны коллизии памяти.
* Оптимальное распределение учитывает архитектуру GPU, размер данных и эффективность параллельной работы.

## 3. Какие сложности возникают при реализации быстрой сортировки на GPU?

* QuickSort сложно адаптировать для GPU, так как алгоритм рекурсивный и требует разделения массива по опорному элементу.
* Проблемы:

  * балансировка нагрузки между потоками (разные части массива могут иметь разный размер);
  * необходимость синхронизации потоков при рекурсивных вызовах;
  * неэффективный доступ к глобальной памяти из-за случайных обращений.
* Из-за этого на GPU чаще используют Merge Sort или Bitonic Sort, более подходящие для параллельной обработки.

## 4. В каких случаях параллельная реализация сортировки на GPU может быть менее эффективной, чем на CPU?

* На **малых массивах** накладные расходы на передачу данных (`cudaMemcpy`) и выделение памяти (`cudaMalloc`) могут превышать выигрыш от параллельной сортировки.
* При алгоритмах с **сильными последовательными зависимостями** CPU, оптимизированный для последовательного выполнения, может работать быстрее.
* Алгоритмы с частыми синхронизациями и неравномерной нагрузкой также теряют эффективность на GPU.

## 5. Почему важно правильно выбирать размер блоков и потоков в CUDA?

* Размер блока определяет, сколько потоков одновременно работает на одном SM.
* Оптимальный выбор блоков и потоков позволяет:

  * скрыть задержки при доступе к глобальной памяти;
  * полностью загрузить вычислительные ядра GPU;
  * избежать нехватки регистров и коллизий в shared memory.
* Например, размеры блоков кратные 32 (warp size) часто дают наилучшую производительность.

## 6. Как использование разделяемой памяти может повлиять на производительность сортировки?

* **Shared memory** — быстрая память внутри блока, доступная всем потокам блока.
* Позволяет:

  * ускорить обмен элементами при сортировке подмассива;
  * уменьшить обращения к медленной глобальной памяти;
  * повысить эффективность параллельного слияния или перестановок элементов.
* Неправильное использование shared memory может привести к коллизиям и снижению производительности.

## 7. Что означает принцип "разделяй и властвуй" в контексте алгоритмов сортировки?

* Принцип: большую задачу разбивают на более мелкие подзадачи того же типа, решают их, затем объединяют результаты.
* В сортировке:

  * массив делится на подмассивы до элементарного размера;
  * подмассивы сортируются (рекурсивно или параллельно);
  * результаты сливаются, получая отсортированный массив.
* Merge Sort и QuickSort — классические примеры реализации этого принципа.

