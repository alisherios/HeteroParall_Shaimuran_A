# HeterogeneousParallelization_Assignment 2

# Assignment 2: OpenMP, CUDA и гетерогенные вычисления

**Astana IT University**  

**Course:** Heterogeneous Parallelization

**Course instructor:** Садвакасова Куралай Жанжигитовна  

**Student:** Жумагулова Карина 

**Group:** ADA-2403M

**Date:** 28.12.2025  

Данный репозиторий содержит решения Assignment 2, посвящённого изучению гетерогенной параллелизации вычислений, а также практическому применению технологий OpenMP и CUDA для ускорения обработки данных.

В рамках работы рассматриваются как теоретические основы гетерогенных вычислений, так и их практическая реализация на примере обработки массивов и алгоритмов сортировки. Особое внимание уделяется сравнению последовательных и параллельных реализаций, анализу производительности и целесообразности использования различных вычислительных архитектур.

В проекте реализованы:
* теоретическое исследование различий между параллельными вычислениями на CPU и GPU;
* работа с массивами в последовательном и параллельном режимах с использованием OpenMP;
* параллельная сортировка выбором на многоядерных процессорах;
* реализация параллельной сортировки слиянием на GPU с использованием CUDA.

Для всех практических заданий проводится измерение времени выполнения, что позволяет наглядно продемонстрировать преимущества и ограничения параллельных вычислений. Работа направлена на формирование понимания того, в каких задачах и при каких условиях гетерогенный подход оказывается наиболее эффективным.

## Структура репозитория

.

├── task_1.md        # Задание 1: теоретическая часть (гетерогенная параллелизация)

├── task_2.cpp       # Задание 2: последовательный и параллельный поиск min/max с OpenMP

├── task_3.cpp       # Задание 3: сортировка выбором (последовательная и параллельная версии)

├── task_4.cpp       # Задание 4: сортировка слиянием на CPU с использованием OpenMP (дополнительно)

├── task_4.ipynb     # Задание 4: сортировка слиянием на GPU с использованием CUDA

├── task_4_cuda_merge_sort.cu    # Задание 4: сортировка слиянием на GPU с использованием CUDA

├── questions.md     # Ответы на контрольные вопросы к Assignment 2

├── README.md        # Общее описание проекта и структура репозитория

### Задание 1 (task1.md)

**Описание**:
Данное задание посвящено теоретическому изучению гетерогенной параллелизации вычислений. В работе рассматриваются принципы распределения задач между CPU и GPU, преимущества такого подхода, а также примеры практического применения.

**Цель задания**:
* Изучить концепцию гетерогенной параллелизации.
* Понять различия между параллельными вычислениями на CPU и GPU.
* Определить преимущества гетерогенного подхода и области его применения.

**Функционал программы/документа**:
* Описание различий архитектур CPU и GPU и их особенностей при параллельной обработке данных.
* Обоснование преимуществ гетерогенной параллелизации, включая ускорение вычислений и оптимальное распределение ресурсов.
* Примеры реальных приложений, использующих гетерогенные вычисления, таких как машинное обучение, научные вычисления и рендеринг графики.

### Задание 2 (task2.cpp)

**Описание:**
Данное задание посвящено практическому изучению **параллельной обработки массивов с использованием OpenMP**. Программа демонстрирует разницу между последовательной и параллельной обработкой данных, а также измеряет влияние параллелизации на время выполнения.

**Цель задания:**

* Создать массив из 10 000 случайных чисел.
* Реализовать поиск **минимального и максимального значений** массива:
  * последовательным способом;
  * с использованием **OpenMP** для параллельной обработки.
* Сравнить время выполнения последовательной и параллельной версий алгоритма и сделать выводы о производительности.

**Функционал программы:**

1. Генерация массива из 10 000 случайных чисел в заданном диапазоне.
2. Последовательный поиск минимального и максимального значения массива с измерением времени.
3. Параллельный поиск минимального и максимального значения массива с использованием OpenMP и измерением времени.
4. Вывод на экран:
   * размер массива;
   * минимальное и максимальное значения;
   * время выполнения для последовательной и параллельной версии.

### Скриншот результатов
<img width="2484" height="1456" alt="image" src="https://github.com/user-attachments/assets/eb364a0c-8ded-4c49-b059-f4935c1cea2e" />

### Задание 3 (task3.cpp)

**Описание:**
Данное задание посвящено **реализации параллельного алгоритма сортировки выбором (Selection Sort) с использованием OpenMP**. Программа демонстрирует разницу между последовательной и параллельной реализацией сортировки и позволяет оценить влияние параллелизации на производительность для массивов разного размера.

**Цель задания:**

* Реализовать **последовательную сортировку выбором** массива.
* Добавить **параллелизм** с помощью директив OpenMP для ускорения работы алгоритма.
* Сравнить производительность последовательной и параллельной версий для массивов размером 1 000 и 10 000 элементов.

**Функционал программы:**

1. Генерация массивов случайных чисел заданного размера (100, 1 000, 10 000, 100 000 элементов).
2. Последовательная сортировка выбором с измерением времени выполнения.
3. Параллельная сортировка выбором с использованием OpenMP с измерением времени выполнения.
4. Вывод на экран:

   * размер массива;
   * время выполнения последовательной и параллельной версии;
   * ускорение параллельной сортировки относительно последовательной.
5. Формулирование выводов о производительности и эффективности параллельного подхода.

### Скриншот результатов
<img width="2484" height="1456" alt="image" src="https://github.com/user-attachments/assets/8b5b8b94-901b-416c-8449-a3b20e262bf5" />

## Задание 4 (task_4_cuda_merge_sort.cu / task4.ipynb)

**Описание:**
Данное задание посвящено реализации **гетерогенной параллельной сортировки слиянием (Merge Sort)** с использованием **GPU (CUDA)** и **CPU (OpenMP)**. В программе показано, как объединить возможности GPU для сортировки подмассивов и CPU для параллельного слияния, чтобы ускорить обработку больших массивов данных.

**Цель задания**

* Реализовать **GPU Merge Sort** с использованием CUDA для ускоренной сортировки подмассивов.
* Использовать **OpenMP на CPU** для параллельного слияния отсортированных подмассивов.
* Проверить корректность сортировки и измерить время выполнения для массивов разного размера.
* Оценить эффективность гетерогенного подхода к параллельным вычислениям.

**Файлы проекта**

* **task_4_cuda_merge_sort.cu** — исходный код с реализацией CUDA Merge Sort и параллельного слияния на CPU.
* **task4.ipynb** — Jupyter Notebook для запуска и тестирования алгоритма в интерактивной среде с визуализацией времени и результатов сортировки.

**Функционал программы**

1. Генерация массивов случайных чисел разных размеров (100, 1 000, 10 000, 100 000, 1 000 000 элементов).
2. **CUDA Kernel** сортирует подмассивы внутри блоков GPU с использованием shared memory.
3. На CPU выполняется параллельное слияние отсортированных блоков с помощью OpenMP.
4. Замер времени выполнения всего процесса сортировки.
5. Проверка корректности сортировки и вывод первых и последних элементов массива.

**Используемые технологии**

* **C++ / CUDA** — ускоренная сортировка на GPU.
* **OpenMP** — параллельное слияние на CPU.
* **std::random / Mersenne Twister** — генерация случайных чисел.
* **chrono** — измерение времени выполнения.
* **Shared memory** — ускорение сортировки внутри CUDA-блоков.

**Применение**

* Изучение **гетерогенных вычислений** с комбинированным использованием CPU и GPU.
* Демонстрация **эффективности параллельных алгоритмов** при работе с большими массивами данных.
* Оценка влияния **параллельного слияния и сортировки на GPU** на производительность.


### Скриншот результатов
<img width="1792" height="1078" alt="image" src="https://github.com/user-attachments/assets/30c2468f-6df5-45a7-beb2-ac2ab1526ec3" />

### Задание 4 (task4.cpp) (дополнительное)

**Описание:**
Данное задание является **дополнением к предыдущим работам** и посвящено **реализации алгоритма сортировки слиянием (Merge Sort) на CPU** в двух вариантах:
последовательном и параллельном с использованием технологии **OpenMP**.
Цель задания — продемонстрировать работу рекурсивного алгоритма сортировки и оценить влияние многопоточности на его производительность.

**Цель задания**

* Реализовать **последовательную версию алгоритма Merge Sort**.
* Реализовать **параллельную версию Merge Sort** с использованием директив OpenMP.
* Сравнить время выполнения последовательной и параллельной реализаций.
* Проверить корректность сортировки и проанализировать полученные результаты.

**Описание реализации**

В программе реализованы следующие компоненты:

* **Функция `merge`** — выполняет слияние двух отсортированных подмассивов.
* **Последовательная версия Merge Sort** — рекурсивная реализация классического алгоритма сортировки слиянием.
* **Параллельная версия Merge Sort** — использует директиву `#pragma omp parallel sections` для параллельной обработки левой и правой частей массива.
* Ограничение глубины параллелизма позволяет избежать создания избыточного количества потоков и сохранить эффективность выполнения.

**Функционал программы**

Программа выполняет следующие действия:

1. Генерирует массивы случайных целых чисел заданного размера
   (100, 1 000, 10 000, 100 000 и 1 000 000 элементов).
2. Выполняет **последовательную сортировку слиянием** с измерением времени выполнения.
3. Выполняет **параллельную сортировку слиянием** с использованием OpenMP.
4. Проверяет корректность сортировки с помощью функции `isSorted`.
5. Выводит на экран:

   * размер массива;
   * режим сортировки (последовательный или параллельный);
   * время выполнения сортировки;
   * результат проверки корректности сортировки;
   * первые и последние элементы массива для визуального контроля.

**Используемые технологии**

* **C++**
* **OpenMP**
* **std::random** — генерация случайных чисел
* **std::chrono** — измерение времени выполнения

### Скриншот результатов
<img width="1876" height="1108" alt="image" src="https://github.com/user-attachments/assets/89e002f1-07f1-438b-b62d-869c3c0ecd30" />


### Контрольные вопросы (`questions.md`)  

Файл содержит ответы на контрольные вопросы по теме гетерогенных вычислений, параллельного программирования на CPU с OpenMP и ускоренных вычислений на GPU с CUDA. Материал охватывает ключевые концепции, принципы и практические аспекты параллельной обработки данных.

**Файл решения:** questions.md
