# Контрольные вопросы к Assignment 2 (OpenMP, CUDA и гетерогенные вычисления)

## 1. Что понимается под гетерогенной параллелизацией?

Гетерогенная параллелизация — это подход, при котором для решения одной задачи используются **разные типы процессоров**, чаще всего CPU и GPU. Последовательные и управляющие части программы выполняются на CPU, а вычислительно сложные, массово-параллельные участки — на GPU. Это позволяет эффективно использовать сильные стороны каждой архитектуры и ускорять обработку больших объёмов данных.

## 2. В чём принципиальные различия архитектур CPU и GPU?

**CPU** оптимизирован для быстрого **последовательного** выполнения сложной логики, управления потоками и ветвления. Обычно имеет несколько мощных ядер.
**GPU** предназначен для **массово-параллельных вычислений**, одновременно обрабатывает тысячи потоков, используя принцип SIMD (Single Instruction, Multiple Data). Его ядра проще, но их много, и они работают синхронно, что позволяет эффективно обрабатывать однотипные операции над большими массивами данных.

## 3. Какие типы задач лучше подходят для выполнения на GPU, а какие — на CPU?

* **GPU:** задачи с большим количеством независимых данных и повторяющимися вычислениями, например обработка графики, рендеринг, численные симуляции, машинное обучение.
* **CPU:** задачи с ветвистой логикой, сложным управлением памятью или последовательными зависимостями, где важна скорость выполнения отдельных инструкций.

## 4. Почему не все алгоритмы эффективно распараллеливаются с использованием OpenMP?

Эффективность OpenMP ограничена:

* **Количество ядер CPU** невелико, поэтому для масштабных задач параллелизм ограничен.
* **Зависимости по данным** могут мешать распараллеливанию: если шаги алгоритма должны выполняться строго последовательно, ускорение почти не получится.
* **Нагрузка на потоки** может быть неравномерной, а синхронизация замедляет работу.

## 5. В чём заключается основная идея алгоритма сортировки слиянием?

Алгоритм сортировки слиянием использует принцип **разделяй и властвуй**: массив делится на подмассивы, каждый сортируется отдельно, после чего результаты сливаются в один отсортированный массив. При параллельной реализации на GPU разные блоки обрабатывают свои части массива одновременно, а затем сливают результаты, что ускоряет обработку больших данных.

## 6. Какие сложности возникают при реализации сортировки слиянием на GPU?

* **Индексация потоков:** необходимо точно рассчитывать, какая часть массива принадлежит каждому потоку (`blockIdx`, `threadIdx`).
* **Доступ к памяти:** частые операции с глобальной памятью замедляют работу, поэтому важно использовать быструю shared memory.
* **Синхронизация потоков:** при слиянии блоков данные должны объединяться согласованно, иначе возможны ошибки или снижение производительности.
* **Рекурсия и ветвления** трудны для GPU, поэтому часто используют итеративные версии алгоритма.

## 7. Как выбор размера блока и сетки влияет на производительность вычислений на GPU?

Размер блока и сетки определяет, как потоки распределяются по мультипроцессорам GPU. Слишком маленький блок — ядра простаивают, слишком большой — может не хватить shared memory. Оптимальная настройка позволяет максимально загрузить GPU, скрыть задержки при доступе к глобальной памяти и повысить общую производительность.

## 8. Почему гетерогенный подход может быть эффективнее использования только CPU или только GPU?

Гетерогенный подход **объединяет сильные стороны CPU и GPU**: CPU подготавливает данные, управляет памятью и инициирует вычисления, а GPU выполняет массово-параллельные операции намного быстрее. После завершения вычислений GPU возвращает результат на CPU, что минимизирует простои и повышает эффективность всего процесса.

