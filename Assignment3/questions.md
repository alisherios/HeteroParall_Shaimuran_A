# Контрольные вопросы — Assignment 3

1. **Какие основные типы памяти существуют в архитектуре CUDA и чем они отличаются по скорости доступа?**
   - **Регистры** — самая быстрая память, приватная для каждого потока.
   - **Shared memory** — быстрая память на кристалле (on-chip), общая для потоков одного блока.
   - **Global memory** — память устройства (DRAM), большой объём и высокая задержка.
   - **Local memory** — логически приватная память потока, но физически хранится в глобальной памяти при нехватке регистров.
   - **Constant memory** — кэшируемая память для констант, эффективна при одинаковых чтениях многими потоками.
   - **Texture memory** — кэшируемые чтения с оптимизацией под пространственную локальность.
   - Также важны **L1/L2 cache** (аппаратные кэши), которые уменьшают задержки при повторных обращениях.

2. **В каких случаях использование разделяемой памяти позволяет ускорить выполнение CUDA-программы?**
   - Когда одни и те же данные многократно используются потоками одного блока.
   - Когда нужно уменьшить число обращений к global memory (например, тильная обработка, частичные суммы, stencil).
   - Когда необходимо переупорядочить данные в блоке для более эффективной дальнейшей обработки.

3. **Как шаблон доступа к глобальной памяти влияет на производительность GPU-программы?**
   - При **коалесцированном доступе** потоки варпа читают/пишут соседние адреса, и память обслуживается меньшим числом транзакций.
   - При **некоалесцированном доступе** обращения разрознены, число транзакций растёт, пропускная способность падает.

4. **Почему одинаковый алгоритм на GPU может показывать разное время выполнения при разных способах обращения к памяти?**
   - Из-за разного количества и размеров транзакций global memory.
   - Из-за различий в кэшировании (L1/L2, constant/texture cache).
   - Из-за конфликтов в shared memory (bank conflicts) и различий в латентности.

5. **Как размер блока потоков влияет на производительность CUDA-ядра?**
   - Влияет на **occupancy** (сколько варпов может одновременно выполняться на SM).
   - Влияет на использование ресурсов: регистры и shared memory на блок.
   - Слишком маленькие блоки могут недогружать SM, слишком большие могут снижать occupancy из-за ограничений по ресурсам.

6. **Что такое варп и почему важно учитывать его при разработке CUDA-программ?**
   - **Варп** — группа потоков (обычно 32), которая выполняется синхронно на одном SM.
   - Ветвления внутри варпа приводят к **divergence** (разные ветки выполняются по очереди), что замедляет выполнение.
   - Коалесценция доступа к памяти также рассматривается на уровне варпа.

7. **Какие факторы необходимо учитывать при выборе конфигурации сетки и блоков потоков?**
   - Размер данных и число операций на элемент.
   - Ограничения GPU: максимальный размер блока, число блоков на SM, доступные регистры и shared memory.
   - Требуемая occupancy и скрытие задержек памяти.
   - Паттерны доступа к памяти и необходимость кооперации потоков внутри блока.

8. **Почему оптимизация CUDA-программы часто начинается с анализа работы с памятью, а не с изменения алгоритма?**
   - Во многих задачах производительность ограничена пропускной способностью и задержками памяти (memory bound).
   - Улучшение коалесценции, уменьшение обращений к global memory, использование shared/кэшей часто дают больший выигрыш, чем локальные изменения арифметики.
